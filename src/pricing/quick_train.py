"""–ë—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏.
"""

import pickle
import re
import warnings
from pathlib import Path

import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

warnings.filterwarnings("ignore")

try:
    from catboost import CatBoostRegressor

    catboost_available = True
except ImportError:
    print("CatBoost –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    catboost_available = False


def quick_train_model():
    """–ë—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –º–∞–ª–æ–π –≤—ã–±–æ—Ä–∫–µ."""
    print("üöÄ –ë—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Ü–µ–Ω–æ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è...")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö
    data_path = "data/train.tsv"
    if not Path(data_path).exists():
        print(f"‚ùå –§–∞–π–ª –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω: {data_path}")
        return False

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–∞–ª–µ–Ω—å–∫—É—é –≤—ã–±–æ—Ä–∫—É
    print("üìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    df = pd.read_csv(data_path, sep="\t", nrows=5000)  # –¢–æ–ª—å–∫–æ 5000 –∑–∞–ø–∏—Å–µ–π

    # –ë—ã—Å—Ç—Ä–∞—è –æ—á–∏—Å—Ç–∫–∞
    df = df[df["price"] > 0].copy()
    df["category_name"] = df["category_name"].fillna("Other")
    df["brand_name"] = df["brand_name"].fillna("Unknown")
    df["item_description"] = df["item_description"].fillna("")

    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π")

    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    print("üîß –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    df["desc_len"] = df["item_description"].str.len()
    df["name_len"] = df["name"].str.len()
    df["has_brand"] = (df["brand_name"] != "Unknown").astype(int)
    df["has_description"] = (df["item_description"] != "").astype(int)

    # –†–∞–∑–±–∏–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    df["cat_main"] = df["category_name"].apply(
        lambda x: x.split("/")[0] if "/" in x else x
    )
    df["cat_sub"] = df["category_name"].apply(
        lambda x: x.split("/")[1] if "/" in x and len(x.split("/")) > 1 else "None"
    )

    # –¢–µ–∫—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    df["desc_words"] = df["item_description"].apply(
        lambda x: len(re.findall(r"\w+", x))
    )
    df["name_words"] = df["name"].apply(lambda x: len(re.findall(r"\w+", x)))

    # TF-IDF (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)
    tfidf_name = TfidfVectorizer(max_features=10, stop_words="english", lowercase=True)
    tfidf_desc = TfidfVectorizer(max_features=10, stop_words="english", lowercase=True)

    tfidf_name_features = tfidf_name.fit_transform(df["name"]).toarray()
    tfidf_desc_features = tfidf_desc.fit_transform(df["item_description"]).toarray()

    # Label encoding
    le_brand = LabelEncoder()
    le_cat_main = LabelEncoder()
    le_cat_sub = LabelEncoder()

    df["brand_enc"] = le_brand.fit_transform(df["brand_name"])
    df["cat_main_enc"] = le_cat_main.fit_transform(df["cat_main"])
    df["cat_sub_enc"] = le_cat_sub.fit_transform(df["cat_sub"])

    # –°–æ–±–∏—Ä–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
    feature_cols = [
        "item_condition_id",
        "shipping",
        "brand_enc",
        "cat_main_enc",
        "cat_sub_enc",
        "desc_len",
        "name_len",
        "has_brand",
        "has_description",
        "desc_words",
        "name_words",
    ]

    X_base = df[feature_cols]

    # –î–æ–±–∞–≤–ª—è–µ–º TF-IDF
    tfidf_name_df = pd.DataFrame(
        tfidf_name_features, columns=[f"name_tfidf_{i}" for i in range(10)]
    )
    tfidf_desc_df = pd.DataFrame(
        tfidf_desc_features, columns=[f"desc_tfidf_{i}" for i in range(10)]
    )

    X = pd.concat([X_base.reset_index(drop=True), tfidf_name_df, tfidf_desc_df], axis=1)
    y = np.log1p(df["price"])

    print(f"üìà –†–∞–∑–º–µ—Ä –º–∞—Ç—Ä–∏—Ü—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {X.shape}")

    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    if not catboost_available:
        print("‚ùå CatBoost –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        return False

    print("ü§ñ –û–±—É—á–µ–Ω–∏–µ CatBoost...")

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    # –ë—ã—Å—Ç—Ä–∞—è –º–æ–¥–µ–ª—å
    model = CatBoostRegressor(
        iterations=50, depth=4, learning_rate=0.2, random_state=42, verbose=10
    )

    model.fit(X_train, y_train, eval_set=(X_test, y_test))

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
    test_pred = model.predict(X_test)
    test_pred_exp = np.expm1(test_pred)
    y_test_exp = np.expm1(y_test)

    rmse = np.sqrt(mean_squared_error(y_test_exp, test_pred_exp))
    print(f"üìä Test RMSE: {rmse:.2f}")

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    print("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")

    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    Path("models").mkdir(exist_ok=True)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    model.save_model("models/catboost_pricing_model.cbm")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º pipeline
    preprocessing_pipeline = {
        "tfidf_name": tfidf_name,
        "tfidf_desc": tfidf_desc,
        "le_brand": le_brand,
        "le_cat_main": le_cat_main,
        "le_cat_sub": le_cat_sub,
        "feature_columns": feature_cols
        + [f"name_tfidf_{i}" for i in range(10)]
        + [f"desc_tfidf_{i}" for i in range(10)],
    }

    with open("models/preprocessing_pipeline.pkl", "wb") as f:
        pickle.dump(preprocessing_pipeline, f)

    print("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞!")
    print("üìÅ –ú–æ–¥–µ–ª—å: models/catboost_pricing_model.cbm")
    print("üìÅ Pipeline: models/preprocessing_pipeline.pkl")

    return True


if __name__ == "__main__":
    success = quick_train_model()
    if success:
        print("\nüéâ –ì–æ—Ç–æ–≤–æ! –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é.")
    else:
        print("\n‚ùå –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å.")
