"""–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ–º —Ü–µ–Ω —Ç–æ–≤–∞—Ä–æ–≤.
–ó–∞–º–µ–Ω—è–µ—Ç LLMService –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã.
"""

import pickle  # nosec B403
import re
from pathlib import Path
from typing import Any, Dict, Optional

import numpy as np
import pandas as pd
from sklearn.preprocessing import LabelEncoder

try:
    from catboost import CatBoostRegressor

    catboost_available = True
except ImportError:
    catboost_available = False

try:
    from dvc.repo import Repo
    dvc_available = True
except ImportError:
    dvc_available = False

from base.config import (
    get_confidence_threshold,
    get_max_price_limit,
    get_min_price_limit,
    get_model_path,
    get_preprocessing_path,
)


class PricingService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —Ü–µ–Ω —Ç–æ–≤–∞—Ä–æ–≤."""

    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞."""
        self.model_path = Path(get_model_path())
        self.preprocessing_path = Path(get_preprocessing_path())
        self.confidence_threshold = get_confidence_threshold()
        self.max_price = get_max_price_limit()
        self.min_price = get_min_price_limit()

        self.model = None
        self.preprocessing_pipeline = None
        self._load_model_and_pipeline()

    def _load_model_and_pipeline(self) -> None:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏ pipeline –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏."""
        # –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏ –∏–∑ DVC remote storage
        if dvc_available:
            try:
                repo = Repo(".")
                print("üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏ –∏–∑ DVC remote storage...")
                repo.pull("models.dvc")
                print("‚úÖ –ú–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ DVC")
            except Exception as e:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑ DVC: {e}")
                print("üìÅ –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –ª–æ–∫–∞–ª—å–Ω—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏...")
        else:
            print("‚ö†Ô∏è  DVC –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        if self.model_path.exists() and catboost_available:
            try:
                self.model = CatBoostRegressor()
                self.model.load_model(str(self.model_path))
                print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {self.model_path}")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
                self.model = None
        else:
            print(
                f"‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–æ –ø—É—Ç–∏ {self.model_path} –∏–ª–∏ CatBoost –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
            )
            self.model = None

        # –ó–∞–≥—Ä—É–∂–∞–µ–º pipeline –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏
        if self.preprocessing_path.exists():
            try:
                with open(self.preprocessing_path, "rb") as f:
                    self.preprocessing_pipeline = pickle.load(f)  # nosec B301
                print(f"‚úÖ Pipeline –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ {self.preprocessing_path}")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ pipeline: {e}")
                self.preprocessing_pipeline = None
        else:
            print(f"‚ùå Pipeline –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ –ø—É—Ç–∏ {self.preprocessing_path}")
            self.preprocessing_pipeline = None

    def _preprocess_single_item(
        self, product_data: Dict[str, Any]
    ) -> Optional[pd.DataFrame]:
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è."""
        if self.preprocessing_pipeline is None:
            raise ValueError("Pipeline –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω")

        try:
            # –°–æ–∑–¥–∞–µ–º DataFrame —Å –æ–¥–Ω–æ–π –∑–∞–ø–∏—Å—å—é
            df = pd.DataFrame([product_data])

            # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏ –∫–∞–∫ –≤ –æ–±—É—á–µ–Ω–∏–∏
            df["category_name"] = df["category_name"].fillna("Other")
            df["brand_name"] = df["brand_name"].fillna("Unknown")
            df["item_description"] = df["item_description"].fillna("")

            # –°–æ–∑–¥–∞–µ–º —Ç–µ –∂–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —á—Ç–æ –∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
            df["desc_len"] = df["item_description"].str.len()
            df["name_len"] = df["name"].str.len()
            df["has_brand"] = (df["brand_name"] != "Unknown").astype(int)
            df["has_description"] = (df["item_description"] != "").astype(int)

            # –†–∞–∑–±–∏–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–∞ —É—Ä–æ–≤–Ω–∏ (—É–ø—Ä–æ—â–µ–Ω–Ω–æ–µ)
            df["cat_main"] = df["category_name"].apply(
                lambda x: x.split("/")[0] if "/" in x else x
            )
            df["cat_sub"] = df["category_name"].apply(
                lambda x: x.split("/")[1]
                if "/" in x and len(x.split("/")) > 1
                else "None"
            )

            # –¢–µ–∫—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            df["desc_words"] = df["item_description"].apply(
                lambda x: len(re.findall(r"\w+", x))
            )
            df["name_words"] = df["name"].apply(lambda x: len(re.findall(r"\w+", x)))

            # TF-IDF –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–µ - 10 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)
            tfidf_name_features = (
                self.preprocessing_pipeline["tfidf_name"]
                .transform(df["name"])
                .toarray()
            )
            tfidf_desc_features = (
                self.preprocessing_pipeline["tfidf_desc"]
                .transform(df["item_description"])
                .toarray()
            )

            tfidf_name_df = pd.DataFrame(
                tfidf_name_features, columns=[f"name_tfidf_{i}" for i in range(10)]
            )
            tfidf_desc_df = pd.DataFrame(
                tfidf_desc_features, columns=[f"desc_tfidf_{i}" for i in range(10)]
            )

            # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            df["brand_enc"] = self._safe_transform(
                self.preprocessing_pipeline["le_brand"], df["brand_name"]
            )
            df["cat_main_enc"] = self._safe_transform(
                self.preprocessing_pipeline["le_cat_main"], df["cat_main"]
            )
            df["cat_sub_enc"] = self._safe_transform(
                self.preprocessing_pipeline["le_cat_sub"], df["cat_sub"]
            )

            # –°–æ–±–∏—Ä–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–µ)
            feature_cols = [
                "item_condition_id",
                "shipping",
                "brand_enc",
                "cat_main_enc",
                "cat_sub_enc",
                "desc_len",
                "name_len",
                "has_brand",
                "has_description",
                "desc_words",
                "name_words",
            ]

            X_base = df[feature_cols].reset_index(drop=True)
            X = pd.concat([X_base, tfidf_name_df, tfidf_desc_df], axis=1)

            return X

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–æ–≤–∞—Ä–∞: {e}")
            return None

    def _safe_transform(self, encoder: LabelEncoder, values: pd.Series) -> pd.Series:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π."""
        try:
            return encoder.transform(values)
        except ValueError:
            # –ï—Å–ª–∏ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é, –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—É—é
            known_classes = set(encoder.classes_)
            values_safe = values.apply(
                lambda x: x if x in known_classes else encoder.classes_[0]
            )
            return encoder.transform(values_safe)

    def _calculate_confidence_score(
        self, prediction: float, features: pd.DataFrame
    ) -> float:
        """–†–∞—Å—á–µ—Ç –æ—Ü–µ–Ω–∫–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏."""
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ:
        # 1. –ù–∞–ª–∏—á–∏—è –±—Ä–µ–Ω–¥–∞
        # 2. –ü–æ–ª–Ω–æ—Ç—ã –æ–ø–∏—Å–∞–Ω–∏—è
        # 3. –î–µ—Ç–∞–ª—å–Ω–æ—Å—Ç–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏

        confidence = 0.5  # –±–∞–∑–æ–≤–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å

        # –ë–æ–Ω—É—Å –∑–∞ –Ω–∞–ª–∏—á–∏–µ –±—Ä–µ–Ω–¥–∞
        if features["has_brand"].iloc[0] == 1:
            confidence += 0.15

        # –ë–æ–Ω—É—Å –∑–∞ –Ω–∞–ª–∏—á–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è
        if features["has_description"].iloc[0] == 1:
            confidence += 0.1

        # –ë–æ–Ω—É—Å –∑–∞ –¥–ª–∏–Ω—É –æ–ø–∏—Å–∞–Ω–∏—è
        desc_len = features["desc_len"].iloc[0]
        if desc_len > 50:
            confidence += 0.1
        elif desc_len > 20:
            confidence += 0.05

        # –®—Ç—Ä–∞—Ñ –∑–∞ —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        if prediction < 5 or prediction > 1000:
            confidence -= 0.2

        return max(0.1, min(1.0, confidence))

    def _get_category_analysis(
        self, product_data: Dict[str, Any], prediction: float
    ) -> Dict[str, str]:
        """–ê–Ω–∞–ª–∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ç–æ–≤–∞—Ä–∞ –¥–ª—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π."""
        category = product_data.get("category_name", "Unknown")
        main_cat = category.split("/")[0] if "/" in category else category

        analysis = {"category": main_cat, "recommendation": "", "market_position": ""}

        # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º (–º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å)
        if prediction < 10:
            analysis["market_position"] = "–ù–∏–∑–∫–∏–π —Ü–µ–Ω–æ–≤–æ–π —Å–µ–≥–º–µ–Ω—Ç"
            analysis[
                "recommendation"
            ] = "–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø–æ–≤—ã—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –æ–ø–∏—Å–∞–Ω–∏—è"
        elif prediction < 50:
            analysis["market_position"] = "–°—Ä–µ–¥–Ω–∏–π —Ü–µ–Ω–æ–≤–æ–π —Å–µ–≥–º–µ–Ω—Ç"
            analysis["recommendation"] = "–•–æ—Ä–æ—à–µ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ü–µ–Ω–∞-–∫–∞—á–µ—Å—Ç–≤–æ"
        else:
            analysis["market_position"] = "–ü—Ä–µ–º–∏—É–º —Å–µ–≥–º–µ–Ω—Ç"
            analysis[
                "recommendation"
            ] = "–£–±–µ–¥–∏—Ç–µ—Å—å –≤ –≤—ã—Å–æ–∫–æ–º –∫–∞—á–µ—Å—Ç–≤–µ —Ç–æ–≤–∞—Ä–∞ –∏ –¥–µ—Ç–∞–ª—å–Ω–æ–º –æ–ø–∏—Å–∞–Ω–∏–∏"

        # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        if "Electronics" in main_cat:
            analysis[
                "recommendation"
            ] += ". –î–ª—è —ç–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫–∏ –≤–∞–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å —Ç–æ—á–Ω—É—é –º–æ–¥–µ–ª—å –∏ —Å–æ—Å—Ç–æ—è–Ω–∏–µ"
        elif "Beauty" in main_cat:
            analysis[
                "recommendation"
            ] += ". –í –∫–æ—Å–º–µ—Ç–∏–∫–µ –≤–∞–∂–Ω—ã —Å—Ä–æ–∫ –≥–æ–¥–Ω–æ—Å—Ç–∏ –∏ –ø–æ–¥–ª–∏–Ω–Ω–æ—Å—Ç—å –±—Ä–µ–Ω–¥–∞"

        return analysis

    async def predict_price(self, product_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —Ü–µ–Ω—ã —Ç–æ–≤–∞—Ä–∞."""
        if self.model is None:
            return {
                "error": "–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞",
                "predicted_price": 0.0,
                "confidence_score": 0.0,
                "price_range": {"min": 0.0, "max": 0.0},
                "category_analysis": {"error": "–ú–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"},
            }

        try:
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            X = self._preprocess_single_item(product_data)
            if X is None:
                raise ValueError("–û—à–∏–±–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö")

            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ (–º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –Ω–∞ log-scale)
            log_prediction = self.model.predict(X)[0]
            prediction = float(np.expm1(log_prediction))  # –û–±—Ä–∞—Ç–Ω–æ–µ –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏–µ

            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ä–∞–∑—É–º–Ω—ã–º–∏ —Ä–∞–º–∫–∞–º–∏
            prediction = max(self.min_price, min(prediction, self.max_price))

            # –†–∞—Å—á–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            confidence_score = self._calculate_confidence_score(prediction, X)

            # –†–∞—Å—á–µ—Ç –¥–∏–∞–ø–∞–∑–æ–Ω–∞ —Ü–µ–Ω (¬± 30% –æ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è)
            price_range = {
                "min": max(self.min_price, prediction * 0.7),
                "max": min(self.max_price, prediction * 1.3),
            }

            # –ê–Ω–∞–ª–∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            category_analysis = self._get_category_analysis(product_data, prediction)

            return {
                "predicted_price": round(prediction, 2),
                "confidence_score": round(confidence_score, 3),
                "price_range": {
                    "min": round(price_range["min"], 2),
                    "max": round(price_range["max"], 2),
                },
                "category_analysis": category_analysis,
            }

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ü–µ–Ω—ã: {e}")
            return {
                "error": str(e),
                "predicted_price": 0.0,
                "confidence_score": 0.0,
                "price_range": {"min": 0.0, "max": 0.0},
                "category_analysis": {"error": "–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏"},
            }

    def get_model_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏."""
        return {
            "model_loaded": self.model is not None,
            "preprocessing_loaded": self.preprocessing_pipeline is not None,
            "model_path": str(self.model_path),
            "preprocessing_path": str(self.preprocessing_path),
            "catboost_available": catboost_available,
            "confidence_threshold": self.confidence_threshold,
            "price_limits": {"min": self.min_price, "max": self.max_price},
        }
