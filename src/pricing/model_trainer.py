"""–ú–æ–¥—É–ª—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è ML –º–æ–¥–µ–ª–∏ —Ü–µ–Ω–æ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è."""

import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, Optional

import numpy as np
import pandas as pd
from catboost import CatBoostRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import train_test_split

try:
    from dvc.repo import Repo
    dvc_available = True
except ImportError:
    dvc_available = False

logger = logging.getLogger(__name__)


class ModelMetrics:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ –º–æ–¥–µ–ª–∏."""

    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫."""
        self.model_version = ""
        self.dataset_stats = {}
        self.feature_importance = {}
        self.metrics = {
            "train": {"rmse": 0.0, "mae": 0.0, "r2": 0.0},
            "test": {"rmse": 0.0, "mae": 0.0, "r2": 0.0},
        }

    def to_dict(self) -> Dict[str, Any]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å."""
        return {
            "model_version": self.model_version,
            "dataset_stats": self.dataset_stats,
            "feature_importance": self.feature_importance,
            "metrics": self.metrics,
        }

    def save(self, path: Path) -> None:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –≤ —Ñ–∞–π–ª."""
        with open(path, "w") as f:
            json.dump(self.to_dict(), f, indent=2)


class PricingModelTrainer:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ —Ü–µ–Ω–æ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è."""

    def __init__(
        self,
        model_dir: str,
        model_name: str = "catboost_pricing_model",
        version: Optional[str] = None,
    ):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–Ω–µ—Ä–∞."""
        self.model_dir = Path(model_dir)
        self.model_name = model_name
        self.version = version or datetime.now().strftime("%Y%m%d_%H%M%S")
        self.version_dir = self.model_dir / self.version
        self.version_dir.mkdir(parents=True, exist_ok=True)

        self.model_path = self.version_dir / f"{model_name}.cbm"
        self.metrics_path = self.version_dir / "metrics.json"

        self.model: Optional[CatBoostRegressor] = None
        self.metrics = ModelMetrics()
        self.metrics.model_version = self.version

        # –°–æ–∑–¥–∞–µ–º symbolic link –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –≤–µ—Ä—Å–∏—é
        latest_link = self.model_dir / "latest"
        if latest_link.exists():
            latest_link.unlink()
        latest_link.symlink_to(self.version_dir)

    def preprocess_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö."""
        logger.info("–ù–∞—á–∏–Ω–∞–µ–º –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö...")

        # –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        df = df.copy()
        df = df.dropna(subset=["price", "name", "category_name"])
        df = df.fillna({"brand_name": "Unknown", "item_description": "", "shipping": 0})

        logger.info(f"–†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {df.shape}")

        logger.info("–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        # –î–ª–∏–Ω–∞ –Ω–∞–∑–≤–∞–Ω–∏—è –∏ –æ–ø–∏—Å–∞–Ω–∏—è
        df["name_len"] = df["name"].str.len()
        df["desc_len"] = df["item_description"].str.len()

        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        df["condition_text"] = df["item_condition_id"].map(
            {
                1: "–ù–æ–≤—ã–π",
                2: "–û—Ç–ª–∏—á–Ω–æ–µ",
                3: "–•–æ—Ä–æ—à–µ–µ",
                4: "–£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ–µ",
                5: "–ü–ª–æ—Ö–æ–µ",
            }
        )

        # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        self.metrics.dataset_stats = {
            "category_counts": df["category_name"].value_counts().to_dict(),
            "brand_counts": df["brand_name"].value_counts().to_dict(),
            "condition_counts": df["condition_text"].value_counts().to_dict(),
            "shipping_counts": df["shipping"].value_counts().to_dict(),
            "price_stats": {
                "min": float(df["price"].min()),
                "max": float(df["price"].max()),
                "mean": float(df["price"].mean()),
                "median": float(df["price"].median()),
            },
        }

        return df

    def train_model(self, df: pd.DataFrame) -> None:
        """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏."""
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        df = self.preprocess_data(df)

        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
        X = df.drop(["price", "name", "item_description"], axis=1)
        y = df["price"]

        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        cat_features = ["category_name", "brand_name", "condition_text"]

        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        self.model = CatBoostRegressor(
            iterations=1000,
            learning_rate=0.1,
            depth=6,
            loss_function="RMSE",
            random_seed=42,
            verbose=False,
            cat_features=cat_features,
            # –û—Ç–∫–ª—é—á–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ catboost_info –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –≤ Docker
            allow_writing_files=False,
        )

        self.model.fit(X_train, y_train)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        feature_importance = dict(zip(X_train.columns, self.model.feature_importances_))
        self.metrics.feature_importance = feature_importance

        # –°—á–∏—Ç–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
        y_train_pred = self.model.predict(X_train)
        y_test_pred = self.model.predict(X_test)

        self.metrics.metrics["train"]["rmse"] = float(
            np.sqrt(mean_squared_error(y_train, y_train_pred))
        )
        self.metrics.metrics["train"]["mae"] = float(
            mean_absolute_error(y_train, y_train_pred)
        )
        self.metrics.metrics["train"]["r2"] = float(r2_score(y_train, y_train_pred))

        self.metrics.metrics["test"]["rmse"] = float(
            np.sqrt(mean_squared_error(y_test, y_test_pred))
        )
        self.metrics.metrics["test"]["mae"] = float(
            mean_absolute_error(y_test, y_test_pred)
        )
        self.metrics.metrics["test"]["r2"] = float(r2_score(y_test, y_test_pred))

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –∏ –º–µ—Ç—Ä–∏–∫–∏
        self.save_model()

    def save_model(self) -> None:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ –º–µ—Ç—Ä–∏–∫."""
        if self.model is None:
            raise RuntimeError("–ú–æ–¥–µ–ª—å –Ω–µ –±—ã–ª–∞ —Å–æ–∑–¥–∞–Ω–∞")
        self.model.save_model(self.model_path)
        self.metrics.save(self.metrics_path)
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–æ–≤–ª—è–µ–º DVC –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –≤ MinIO
        if dvc_available:
            try:
                logger.info("üîÑ –û–±–Ω–æ–≤–ª—è–µ–º –º–æ–¥–µ–ª–∏ –≤ DVC –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –≤ MinIO...")
                repo = Repo(".")
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ DVC
                repo.add("models")
                logger.info("‚úÖ –ú–æ–¥–µ–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ DVC")
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ remote storage
                repo.push("models.dvc")
                logger.info("‚úÖ –ú–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ MinIO")
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è DVC: {e}")
                logger.info("üìÅ –ú–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –ª–æ–∫–∞–ª—å–Ω–æ")
        else:
            logger.warning("‚ö†Ô∏è  DVC –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –º–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã —Ç–æ–ª—å–∫–æ –ª–æ–∫–∞–ª—å–Ω–æ")
